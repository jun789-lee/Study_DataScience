{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f78920dc",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-12T06:22:10.626836Z",
     "iopub.status.busy": "2025-06-12T06:22:10.626619Z",
     "iopub.status.idle": "2025-06-12T06:22:12.012233Z",
     "shell.execute_reply": "2025-06-12T06:22:12.011277Z"
    },
    "papermill": {
     "duration": 1.392958,
     "end_time": "2025-06-12T06:22:12.013482",
     "exception": false,
     "start_time": "2025-06-12T06:22:10.620524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset\n",
      "statoil-iceberg-classifier-challenge\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bb3bad97",
   "metadata": {
    "papermill": {
     "duration": 0.004205,
     "end_time": "2025-06-12T06:22:12.023145",
     "exception": false,
     "start_time": "2025-06-12T06:22:12.018940",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Runs on GPU there is some compatiblity issue with CPUs\n",
    "\n",
    "1. Hyperparameters in Deep Learning are many, tuning them will take weeks or months. Generally researchers do this tuning and publish paper when they find a nice set of architecture which performs better than others.\n",
    "\n",
    "2. Since the model is pre-trained, it converges very fast and but still you need GPU to use this. Due to some library issues, it does not work on CPU.\n",
    "\n",
    "3. For our purpose, we can use those architectures, which are made available by those researchers to use.\n",
    "\n",
    "4. Using those pretrained nets, layers of which already `knows` how to extract features, we do not have to tune the hyperparameters. Sine they are already trained of some dataset(say imagenet), their pre-trained weights provide a good initilaization of weights and because of this, our Convolutional Network converges very fast otherwise, it can take days on these deep architectures. That's the idea behind **Transfer Learning**. Examples of which are VGG 16, InceptionNet, goolenet, Resnet etc.\n",
    "\n",
    "5. In this kernel we will use pre-trained VGG-16 network which performs very well on small size images.\n",
    "   - **VGG architecture has proved to work well on small sized images**. I expected it to work well for this dataset as well.\n",
    "  \n",
    "6. The code also includes **the data augmentation** steps, thus considerable improving the performance.\n",
    "\n",
    "7. GPU is needed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d71f6a4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T06:22:12.033510Z",
     "iopub.status.busy": "2025-06-12T06:22:12.032843Z",
     "iopub.status.idle": "2025-06-12T06:22:13.148701Z",
     "shell.execute_reply": "2025-06-12T06:22:13.147952Z"
    },
    "papermill": {
     "duration": 1.122496,
     "end_time": "2025-06-12T06:22:13.150052",
     "exception": false,
     "start_time": "2025-06-12T06:22:12.027556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from os.path import join as opj\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pylab\n",
    "plt.rcParams['figure.figsize'] = 10,10\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af2db5d",
   "metadata": {
    "papermill": {
     "duration": 0.004048,
     "end_time": "2025-06-12T06:22:13.158720",
     "exception": false,
     "start_time": "2025-06-12T06:22:13.154672",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### 모르는 내용들\n",
    "1. Stratified Shuffle Split\n",
    "- Spllit : 분할. 데이터셋을 훈련과 cv셋으로 나누는 것.\n",
    "- Shuffle : 샘플링\n",
    "- Stratified : 타켓 분포에 맞춰서 샘플링\n",
    "\n",
    "2. from os.path import join as opj\n",
    "- 파일 경로를 효율적이고 안전하게 다루기 위함\n",
    "- os : 파이썬이 다양한 운영체제 소프트웨어와 상호작용할 수 있게 해주는 내장 모듈\n",
    "- os.path : 파일 경로를 다루는 함수들을 포함하고 있음\n",
    "- join from os.path : 여러 개의 문자열을 지능적으로 결합하여, 하나의 파일 경로로 만들어줌.\n",
    "- opj -> os.path.join과 같은 긴 이름을 짧게!\n",
    "\n",
    "3. from mpl_toolkits.mplot3d imprt Axes3D\n",
    "- mpt_toolkits : matplotlib에서 특수한 그래프 기능을 추가해주는 툴킷 모음\n",
    "- mplot3d : 3D 산점도, 3D 표면도 등 3D 그래프를 그리기 위한 전용 툴킷\n",
    "- Axes3D : 3차원 축을 생성하는 핵심 객체."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "675eb534",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T06:22:13.168702Z",
     "iopub.status.busy": "2025-06-12T06:22:13.168126Z",
     "iopub.status.idle": "2025-06-12T06:22:36.197664Z",
     "shell.execute_reply": "2025-06-12T06:22:36.196828Z"
    },
    "papermill": {
     "duration": 23.036341,
     "end_time": "2025-06-12T06:22:36.199193",
     "exception": false,
     "start_time": "2025-06-12T06:22:13.162852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_json(\"/kaggle/input/dataset/train.json/data/processed/train.json\")\n",
    "target_train = train['is_iceberg']\n",
    "test = pd.read_json('/kaggle/input/dataset/test.json/data/processed/test.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85783b2",
   "metadata": {
    "papermill": {
     "duration": 0.00419,
     "end_time": "2025-06-12T06:22:36.208039",
     "exception": false,
     "start_time": "2025-06-12T06:22:36.203849",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Keras provoed the implementation of pretrained VGG, in it's library so, we do not have to build the network by ourselves. Here we are removing the last layer of VGG and putting our sigmoid layer for binary predictions.\n",
    "\n",
    "The following code will NOT WORK, since on kaggle notebook, the weights of model cannot be downloaded. However, you can copy paste the code in your own notebook to make it work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1caa30a",
   "metadata": {
    "papermill": {
     "duration": 0.003963,
     "end_time": "2025-06-12T06:22:36.216090",
     "exception": false,
     "start_time": "2025-06-12T06:22:36.212127",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### json 파일 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fba4f6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T06:22:36.225303Z",
     "iopub.status.busy": "2025-06-12T06:22:36.225072Z",
     "iopub.status.idle": "2025-06-12T06:22:36.253066Z",
     "shell.execute_reply": "2025-06-12T06:22:36.252476Z"
    },
    "papermill": {
     "duration": 0.03392,
     "end_time": "2025-06-12T06:22:36.254183",
     "exception": false,
     "start_time": "2025-06-12T06:22:36.220263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>band_1</th>\n",
       "      <th>band_2</th>\n",
       "      <th>inc_angle</th>\n",
       "      <th>is_iceberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dfd5f913</td>\n",
       "      <td>[-27.878360999999998, -27.15416, -28.668615, -...</td>\n",
       "      <td>[-27.154118, -29.537888, -31.0306, -32.190483,...</td>\n",
       "      <td>43.9239</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e25388fd</td>\n",
       "      <td>[-12.242375, -14.920304999999999, -14.920363, ...</td>\n",
       "      <td>[-31.506321, -27.984554, -26.645678, -23.76760...</td>\n",
       "      <td>38.1562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58b2aaa0</td>\n",
       "      <td>[-24.603676, -24.603714, -24.871029, -23.15277...</td>\n",
       "      <td>[-24.870956, -24.092632, -20.653963, -19.41104...</td>\n",
       "      <td>45.2859</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4cfc3a18</td>\n",
       "      <td>[-22.454607, -23.082819, -23.998013, -23.99805...</td>\n",
       "      <td>[-27.889421, -27.519794, -27.165262, -29.10350...</td>\n",
       "      <td>43.8306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>271f93f4</td>\n",
       "      <td>[-26.006956, -23.164886, -23.164886, -26.89116...</td>\n",
       "      <td>[-27.206915, -30.259186, -30.259186, -23.16495...</td>\n",
       "      <td>35.6256</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                             band_1  \\\n",
       "0  dfd5f913  [-27.878360999999998, -27.15416, -28.668615, -...   \n",
       "1  e25388fd  [-12.242375, -14.920304999999999, -14.920363, ...   \n",
       "2  58b2aaa0  [-24.603676, -24.603714, -24.871029, -23.15277...   \n",
       "3  4cfc3a18  [-22.454607, -23.082819, -23.998013, -23.99805...   \n",
       "4  271f93f4  [-26.006956, -23.164886, -23.164886, -26.89116...   \n",
       "\n",
       "                                              band_2 inc_angle  is_iceberg  \n",
       "0  [-27.154118, -29.537888, -31.0306, -32.190483,...   43.9239           0  \n",
       "1  [-31.506321, -27.984554, -26.645678, -23.76760...   38.1562           0  \n",
       "2  [-24.870956, -24.092632, -20.653963, -19.41104...   45.2859           1  \n",
       "3  [-27.889421, -27.519794, -27.165262, -29.10350...   43.8306           0  \n",
       "4  [-27.206915, -30.259186, -30.259186, -23.16495...   35.6256           0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78eab6cd",
   "metadata": {
    "papermill": {
     "duration": 0.004238,
     "end_time": "2025-06-12T06:22:36.262851",
     "exception": false,
     "start_time": "2025-06-12T06:22:36.258613",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Block 1 데이터 로딩 및 전처리 Data Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f916c74f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T06:22:36.272980Z",
     "iopub.status.busy": "2025-06-12T06:22:36.272360Z",
     "iopub.status.idle": "2025-06-12T06:22:36.283216Z",
     "shell.execute_reply": "2025-06-12T06:22:36.282470Z"
    },
    "papermill": {
     "duration": 0.017162,
     "end_time": "2025-06-12T06:22:36.284321",
     "exception": false,
     "start_time": "2025-06-12T06:22:36.267159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/1143497653.py:9: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  train['inc_angle'] = train['inc_angle'].fillna(method = 'pad')\n"
     ]
    }
   ],
   "source": [
    "# 타겟 변수를 따로 저장\n",
    "target_train = train['is_iceberg']\n",
    "\n",
    "# inc_angle 열을 숫자 형태로 변환. 변환할 수 없는 값은 NaA 결측치 처리\n",
    "test['inc_angle'] = pd.to_numeric(test['inc_angle'], errors = 'coerce')\n",
    "train['inc_angle'] = pd.to_numeric(test['inc_angle'], errors = 'coerce')\n",
    "\n",
    "# 결측치를 발 ㅗ이전의 유효한 값으로 채움 (pad 방식)\n",
    "train['inc_angle'] = train['inc_angle'].fillna(method = 'pad')\n",
    "\n",
    "# 전처리된 각도 정보를 새로운 변수에 할당\n",
    "X_angle = train['inc_angle']\n",
    "X_test_angle = test['inc_angle']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16d50ed",
   "metadata": {
    "papermill": {
     "duration": 0.004061,
     "end_time": "2025-06-12T06:22:36.292725",
     "exception": false,
     "start_time": "2025-06-12T06:22:36.288664",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Concept\n",
    "\n",
    "1. `pd.to_numeric(..., erros = 'coerce')` : inc_angle(입사각) 열에는 가끔 숫자가 아닌 문자열 na이 섞여있을 수 있는데, 이 열의 모든 값을 숫자 (float)타입으로 바꾸는 역할! `erros = 'coerce'` 옵션은 만약 어떤 값이 숫자로 바뀔 수 없다면, 그 값을 강제로 NaN으로 만들라는 의미.\n",
    "\n",
    "2. `fillna(method='pad')` : `coerce` 옵션 떄문에 생긴 NaN 값들을 처리하는 것. NaN 결측치를 pad 방식으로 채우는데, pad 방식은, 바로 위에 있는 유효한 값으로 그대로 복사해서 채워넣는 것! 데이터가 특정 순서로 정렬되어있을 때 유용한 방식."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0975409e",
   "metadata": {
    "papermill": {
     "duration": 0.004058,
     "end_time": "2025-06-12T06:22:36.301003",
     "exception": false,
     "start_time": "2025-06-12T06:22:36.296945",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 블록 2 : 이미지 데이터 준비 및 채널 결합. (Image Data Preparation & Channel Combination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84c86557",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T06:22:36.310663Z",
     "iopub.status.busy": "2025-06-12T06:22:36.310464Z",
     "iopub.status.idle": "2025-06-12T06:22:43.495031Z",
     "shell.execute_reply": "2025-06-12T06:22:43.494399Z"
    },
    "papermill": {
     "duration": 7.190797,
     "end_time": "2025-06-12T06:22:43.496439",
     "exception": false,
     "start_time": "2025-06-12T06:22:36.305642",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 훈련 데이터의 band_1, band_2 이미지 데이터를 75x75 크기의 넘파이 배열로 변환\n",
    "X_band_1 = np.array([np.array(band).astype(np.float32).reshape(75,75) for band in train['band_1']])\n",
    "X_band_2 = np.array([np.array(band).astype(np.float32).reshape(75,75) for band in train['band_2']])\n",
    "\n",
    "# band_1과 band_2의 평균값으로 세번 째 채널 생성\n",
    "X_band_3 = (X_band_1 + X_band_2) / 2\n",
    "\n",
    "# 결합 concatenate\n",
    "X_train = np.concatenate([X_band_1[:,:,:,np.newaxis],\n",
    "                          X_band_2[:,:,:,np.newaxis],\n",
    "                          X_band_3[:,:,:,np.newaxis]], axis = -1)\n",
    "\n",
    "# Test Data Set에 대해서도 위와 동일하 과정을 반복\n",
    "X_band_test_1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test['band_1']])\n",
    "X_band_test_2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test['band_2']])\n",
    "X_band_test_3 = (X_band_test_1 + X_band_test_2) / 2\n",
    "X_test = np.concatenate([X_band_test_1[:,:,:, np.newaxis],\n",
    "                         X_band_test_2[:,:,:, np.newaxis],\n",
    "                         X_band_test_3[:,:,:, np.newaxis]], axis = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36be5e7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-06T06:25:18.539626Z",
     "iopub.status.busy": "2025-06-06T06:25:18.538965Z",
     "iopub.status.idle": "2025-06-06T06:25:18.542830Z",
     "shell.execute_reply": "2025-06-06T06:25:18.542067Z",
     "shell.execute_reply.started": "2025-06-06T06:25:18.539603Z"
    },
    "papermill": {
     "duration": 0.004538,
     "end_time": "2025-06-12T06:22:43.505969",
     "exception": false,
     "start_time": "2025-06-12T06:22:43.501431",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 블록 3 : Keras 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2d20d4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T06:22:43.516271Z",
     "iopub.status.busy": "2025-06-12T06:22:43.516023Z",
     "iopub.status.idle": "2025-06-12T06:22:59.166124Z",
     "shell.execute_reply": "2025-06-12T06:22:59.165541Z"
    },
    "papermill": {
     "duration": 15.656681,
     "end_time": "2025-06-12T06:22:59.167496",
     "exception": false,
     "start_time": "2025-06-12T06:22:43.510815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-12 06:22:45.050271: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749709365.213667      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749709365.261230      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "# Keras and related library import\n",
    "\n",
    "# TensorFlow와 Keras 관련 라이브러리 임포트\n",
    "\n",
    "# 기본 시각화 도구\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# 1. 옵티마이저 (Optimizers)\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam, SGD\n",
    "\n",
    "# 2. 모델 아키텍처 (Model Architecture)\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (Conv2D, MaxPooling2D, Dense, Dropout, \n",
    "                                     Input, Flatten, Activation, GlobalMaxPooling2D, \n",
    "                                     BatchNormalization, Concatenate, concatenate, \n",
    "                                     LSTM, LeakyReLU, PReLU)\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "# 3. 훈련 보조 도구 (Training Helpers)\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "\n",
    "# 4. 사전 학습된 모델 및 데이터셋 (Pre-trained Models & Datasets)\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275efe03",
   "metadata": {
    "papermill": {
     "duration": 0.004422,
     "end_time": "2025-06-12T06:22:59.176781",
     "exception": false,
     "start_time": "2025-06-12T06:22:59.172359",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### 라이브러리 역할 및 딥러닝 개념 설명\n",
    "\n",
    "0. 기본 시각화 도구\n",
    "- matplotlib\n",
    "\n",
    "1. 옵티마이저\n",
    "- `from tensorflow.keras.optimizers import RMSprop, Adam, SGD`\n",
    "    - 딥러닝 개념: 최적화. 옵티마이저는 가중치의 학습을 어떻게 최적화할 것인지 정하는 알고리즘.\n",
    "        -  SGD : Stochastic Gradient Descent : 기본 경사하강\n",
    "        -  RMSprop, Adam : SGD의 단점을 보완하여 더 빠르고 안정적으로 최적의 가중치를 찾도록 개선된 알고리즘. 아담은, 방향과 속도를 가중평균치를 이용하여 빠르게 수렴하도록 해줌!\n",
    "\n",
    "2. Model Architecture\n",
    "- `from tensorflow.keras.models import Sequential, Model`\n",
    "- 이 그룹은 신경망의 구조, 즉 뼈대를 만드는 데 사용되는 부품들.\n",
    "- 역할 : 케라스에서 모델의 전체 구조를 정의하는 방법은 총 두 가지.\n",
    "    - 딥러닝 개념 : 신경망 아키텍쳐 설계\n",
    "        - Sequential : 이름처럼, 레이어를 순차적으로 차곡차곡 쌓아 올리는 간단한 모델을 만들 때 사용\n",
    "        - Model : Input과 함께 사용되며, 여러 개의 입력과 출력을 갖거나, 중간에 레이어가 갈라지고 합쳐지는 등, 복잡한 비선형 구조의 모델(functional API)을 만들 때 사용.\n",
    " \n",
    "- `from tensorflow.keras.layers import (Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, Activation, GlobalMaxPooling2D, BatchNormalization, Concatenate, concatenate, LSTM, LeakyReLU, PReLU)`\n",
    "    - 역할 : 신경망을 구성하는 각 층 layer. 각 레이어는 특정 계산을 수행!\n",
    "    - 딥러닝 개념 :\n",
    "        - Conv2D, MaxPoolig2D, GlobaldMaxPooling2D : 합성곱 신경망의 핵심 레이어.\n",
    "            - Conv2D :  이미지에 필터를 적용해, feature map 생성 (각 필터마다, 경계산, 질감 감지라던가)\n",
    "            - MaxPooling2D : 특징맵의 크기르 줄여, 중요한 특징만 남기고 계산량 감소시킴\n",
    "         - Input, Flatten, Dense : 완전 연결 신경망 구성\n",
    "             - Input : 모델의 입력을 정의 (Functional API에서 사용)\n",
    "             - Flatten : 다차원의 특징맵을 1차원 벡터 평탄화\n",
    "             - Dense : 기본 신경망 레이어\n",
    "         - Activation, LeakyReLu, PReLu : 활성화 함수. 레이어에 비선형성을 추가.\n",
    "         - Dropout : 정규화 기법 중 하나. 매 학습마다, 무작위로 특정 뉴런 비활성화\n",
    "         - BatchNormalization : 정규화 기법 중 하나. 각 레이어를 통과한 데이터의 분포를 평균 0, 분산 1로 정규화하여, 학습 과정을 안정시키고 속도를 향상.\n",
    "         - Concatenate, concatenate, LSTM : 조금 더 특수한 레이어들.\n",
    "             - Concatenate : 여러 레이어의 출력을 하나로 합칠 때 사용(다중 입력 모델)\n",
    "             - LSTM : 순환 신경망 RNN의 한 종류로, 시계열 데이터나 자영너처럼 순서가 중요한 데이터를 처리하는 데 사용.\n",
    "\n",
    "3. Training Heleprs 훈련 보조 도구\n",
    "`from tensorflow.keras.preprocessing.image import ImageDataGenerator`\n",
    "    - 역할 : 실시간으로 이미지 데이터를 증강(augment)하여 모델에 공급하는 제너레이터를 만듦\n",
    "    - 딥러닝 개념 : 데이터 증강. 가지고 있는 이미지 데이터에 회전,확대/축소/좌우 반전 등 미세한 변형을 가하여 훈련 데이터의 양을 인위적으로 늘리는 기술. 모델이 다양한 상황에 대처하는 능력(일반화 성능)을 높여주고 과적합을 줄이는 데 큰 도움이 됨.\n",
    "\n",
    "- `from tensorflow.keras.callbakcs import ModelCheckpoint, callback, EarlyStopping`\n",
    "    - 역할 : 모델 훈련 과정 중간중간에 특정 작업을 수행하도록 하는 callback 함수들\n",
    "    - 딥러닝 개념 : 훈련 모니터링 및 제어\n",
    "        - ModelCheckpoint : 훈련 중 검증 성능이 가장 좋았을 때의 모델 가중치를 자동으로 저장\n",
    "        - EarlyStopping : 검증 성능이 일정 기간 동안 더 이상 향상되지 않으면, 훈련을 조기 종료시켜 시간 낭비와 과적합을 막음.\n",
    "\n",
    "4. Pre-trained Models & Datasets\n",
    "- `from tensorflow.keras.datasets import cifar10`\n",
    "    - 역할 : cifar10은 클래스 10개로 구성된 60000장의 작은 이미지 데이터셋. Keras는 이처럼 널리 사용되는 벤치마크 데이터셋을 쉽게 불러올 수 있는 기능을 제공\n",
    "    - 딥러닝 개념 : 벤치마킹(Benchmarking). 표준화된 데이터셋을 사용하면, 내가 만든 모델의 성능을 다른 모델들과 객관적으로 비교할 수 있음.\n",
    "- `from tensorflow.keras.apllications... import VGG16, InceptionV3, ...`\n",
    "    - 역할 : ImageNet과 같은 거대한 데이터셋으로 이미 학습이 완료된, 성능이 검증된 유명한 모델 아키텍처들을 불러옴.\n",
    "    - 딥러닝 개념 : 전이학습 (Transfer Learning) : '바퀴를 다시 발명하지 않는다'는 철학과 같다! 수백만 장의 이미지로 학습된 모델이 가진 지식(특징 추출 능력)을 나의 새로운 (상대적으로 작은)데이터셋 문제에 가져와 활용하는 기법. 밑바닥부터 학습하는 것보다 훨씬 빠르고 높은 성능을 얻을 수 있어 널리 사용됨.\n",
    "- `from tensorflow.keras.applications.vgg16 import process_input`\n",
    "    - 역할 : 특정 사전 학습 모델(여기서는 vgg16)이 학습될 때 사용했던 것과 똑같은 방식으로 입력 이미지를 전처리(e.g., 픽셀 값 스케일링, 채널 순서 변경 등)해주는 함수\n",
    "    - 딥러닝 개념 : 모델별 전처리 일관성. 전이학습을 제대로 수행하려면, 내가 사용할 이미지도 원래 모델이 학습했던 데이터와 동일한 분포 형식으로 만들어주어야 함! 그래야 이 모델이 그 역할을 정확히 수행해줌. 요리사에는 요리사에게 걸맞는 재료를!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285bd0a2",
   "metadata": {
    "papermill": {
     "duration": 0.004195,
     "end_time": "2025-06-12T06:22:59.185338",
     "exception": false,
     "start_time": "2025-06-12T06:22:59.181143",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 몰랐던 내용들 정리\n",
    "\n",
    "1. Adam 옵티마이저 : Momentum과 RMSprop의 결합\n",
    "Adam OPtimizer는 현재 가장 널리 쓰이는 최적화 알고리즘 중 하나. 그 이유는 경사하강법의 두 가지 주요한 문제점을 해결하는 Momentum과 RMSprop의 장점을 모두 채택했기 때문!\n",
    "\n",
    "가. Momentum(관성)\n",
    "- 해결하려는 문제 : 일반적인 경사하강법은 경사의 방향이 계속해서 크게 바뀔 때(지그재그로 움직이므로) 학습이 매우 느려지는 문제가 있습니다.\n",
    "- 핵심 아이디어 : 모멘텀은 이름처럼 물리적인 관성의 개념을 도입합니다. 현재의 경사 방향 뿐만 아니라, 과거에 이동해왔던 방향을 일정 부분 유지하려는 설징을 추가!\n",
    "    - 작동 방식 : '지수 가중 이동 평균 Exponentially Weighted Moving Average'를 사용하여, 과거 경사들의 평균적인 방향 계산. 이로 인해, 불필요한 진동이 줄어들고, 직선적으로 수렴하게 만듦.\n",
    " \n",
    "나. RMSprop Root mean Sqaure Propagation\n",
    "- 해결하려는 문제 : 모든 파라미터(가중치)에 동일한 학습률을 적용하는 것은 비효율적. 어떤 파라미터는 이미 최적값에 가까워 조금만 움직여야 하고, 어떤 파라미터는 아직 멀리 있어 더 많이 움직여야 함.\n",
    "- 핵심 아이디어 : 각 파라미터마다 적응적인 adaptive 학습률을 적용. 즉, 파라미터의 변화가 많았는지 적었는지에 따라 학습률을 조정.\n",
    "    - 작동 방식 : 이 역시, 지수 가중 이동 평균을 사용하지만, 경사의 방향이 아닌, 경사 제곱값의 평균을 추적. 이는 경사 크기의 변화량을 나타냄.\n",
    "    - 효과 :\n",
    "        - 1. 적응적 학습률 : 최근에 경사가 컸던 파라미터는 학습률을 작게 만들고, 경사가 작았던 파라미터는 학습률을 크게 만듦\n",
    "          2. 안정적인 학습 : 이를 통해, 변화가 심한 파라미터는 조심스럽게 업데이트하고, 변화가 거의 없던 파라미터는 더 과감하게 업데이트하여 ,전체적으로 안정적ㅈ이고 효율적인 학습이 가능.\n",
    "     \n",
    "Adam (Adaptive Moemnt Estimation)\n",
    "Adam은 이 두 가지를 모두 합친 것. 이동 방향은 Momentum처럼 과거의 경사 방향을 고려하여 결정하고, 학습률의 크기는 RMSprop처럼 과거 경사 크기에 따라 적응적으로 조절.\n",
    "\n",
    "2. MaxPooling2D vs GlobalMaxPooling 2D\n",
    "두 레이어 모두 CNN에서 특징 맵의 크기를 줄리는 풀링 연산을 수행하지만, 그 방식과 목적에서 명확한 차이가 존재.\n",
    "\n",
    "가. Maxpooling2D\n",
    "- 작동 방식 : pool_size (e.g. 2x2)와 strides (e.g., 2)에 따라, 특징맵 위를 창문 window이 이동하면서, 각 창문 영역에서 가장 큰 값 하나만을 추출.\n",
    "- 목적 :\n",
    "    1. 특징 맵의 공가적 차원 축소 : 계산량을 줄이고, 모델의 파라미터 감소\n",
    "    2. 지역적 특징 강조. 특정 지역에서 가장 활성화가 강한 특징을 뽑아내어, 이미지 내 객체의 위치가 조금 변하거나, 회전하더라도 동일한 특징을 잡아낼 수 있도록 함. Translation Invariance\n",
    "- 사용 위치 : 주로 CNN 아키텍처의 중간 부분에서 Conv2D 레이어 다음에 반복적으로 사용되어, 점진적으로 이미지의 공간적 크기를 줄이고 특징을 압축.\n",
    "\n",
    "나. GlobalMaxPooling2D\n",
    "- 작동 방식 : 창문을 이동시키는 것이 아니라, 각 특징 맵 채널 전체에서 가장 큰 값 하나만을 추출. (8, 8, 128) 크기의 특징맵이 입력되면, 각 128개의 채널에서 가장 큰 값 하나씩을 뽑아 (128, ) 크기의 1차원 벡터를 출력.\n",
    "- 목적 :\n",
    "    1. 분류를 위한 최종 벡터화 : CNN의 특징 추출 부분의 최종 출력을 분류기 Classifier에 넣기 전에, 다차원의 특징맵을 1차원 벡터로 변환하는 역할. Flatten 레이어와 유사한 목적!\n",
    "    2. 파라미터 수 감소 : Flatten은 모든 값을 그대로 펴기 때문에, 파라미터 수가 매우 커질 수 있지만, GlobalMaxPooling2D는 채널당 하나의 값만 남기므로, 파라미터 수를 획기적으로 줄여, 과적합을 방지.\n",
    "- 사용 위치 : 주로, CNN 아키텍처의 맨 마지막, 즉 특징 추출 부분과 완전 연결 분류기 사이에 위치.\n",
    "\n",
    "3. 활성화 함수 : Activation, LeakyReLU, PReLU\n",
    "\n",
    "가. Activation은 Keras에서 활성화 함수를 하나의 독립적인 레이어처럼 사용할 때 씀. `Dense(units = 64, activation = 'relu')`처럼 레이어의 인자로 직접 지정할 수도 있지만, Activation('relu')처럼 분리하면 코드의 유연성이 높아짐.\n",
    "\n",
    "나. LeakyReLU\n",
    "- 배경 : 가장 널리 쓰이는 활성화 함수인 ReLU는 입력값이 0보다 작으면 항상 0을 출력. 이로 인해 일부 뉴런이 훈련 과정에서 아예 비활성화되어 다시는 활성화되지 않는 Dying ReLU 문제가 발생.\n",
    "- 핵심 아이디어 : 입력값이 0보다 작을 때 0을 출력하는 대신, 아주 작은 음수 알파 0.01을 적용.\n",
    "\n",
    "다. PReLU (Parametric ReLU)\n",
    "- 배경: LeakyReLU의 아이디어를 한 단계 더 발전시킨 것입니다.\n",
    "\n",
    "- 핵심 아이디어: LeakyReLU에서 음수 기울기 α를 0.01과 같은 고정된 값으로 사용하는 대신, 이 α 값 자체를 **학습 가능한 파라미터(trainable parameter)**로 만듭니다.\n",
    "\n",
    "- 수식: LeakyReLU와 동일하지만, α가 역전파(backpropagation)를 통해 데이터로부터 최적의 값을 학습합니다.\n",
    "\n",
    "- \n",
    "- 효과: 데이터에 가장 적합한 음수 기울기를 모델이 스스로 찾게 하므로, LeakyReLU보다 더 유연하고 높은 성능을 기대할 수 있습니다. 다만, 파라미터가 추가되므로 과적합의 위험이 미세하게 증가할 수 있습니다.\n",
    "\n",
    "\n",
    "4. 특수한 레이어: Concatenate, LSTM\n",
    "\n",
    "\n",
    "가. Concatenate\n",
    "- 역할: 두 개 이상의 레이어 출력을 하나의 텐서(tensor)로 합치는 역할을 합니다.\n",
    "- 작동 방식: 지정된 축(axis)을 기준으로 텐서들을 그대로 이어 붙입니다. 예를 들어, (None, 128) 크기의 텐서 A와 (None, 64) 크기의 텐서 B를 마지막 축(axis=-1) 기준으로 합치면, (None, 192) 크기의 새로운 텐서가 생성됩니다.\n",
    "- 주요 사용 사례:\n",
    "    - 다중 입력 모델 (Multi-input Models): 이미지 특징과 메타데이터(e.g., 각도, 나이) 특징을 결합하는 것처럼, 서로 다른 소스에서 나온 특징들을 합쳐서 최종 판단을 내리는 모델을 만들 때 필수적입니다.\n",
    "    - Inception, ResNet과 같은 복잡한 아키텍처: 모델 내부에서 여러 갈래로 나뉜 경로의 출력을 다시 하나로 합칠 때 사용됩니다.\n",
    "      \n",
    "나. LSTM (Long Short-Term Memory)\n",
    "- 역할: 순서(sequence)가 있는 데이터의 패턴을 학습하기 위해 설계된 **순환 신경망(RNN)**의 한 종류입니다.\n",
    "- 해결하려는 문제: 기본적인 RNN은 시퀀스가 길어질수록 앞쪽의 정보가 뒤쪽으로 전달되면서 점점 희미해지는 **'장기 의존성 문제(Long-term dependency problem)'**를 가집니다. (e.g., 긴 문장의 맨 앞에 있는 주어를 문장 끝에서 기억하지 못하는 문제)\n",
    "- 핵심 아이디어: '셀 상태(Cell State)'라는 컨베이어 벨트 같은 정보 흐름을 만들고, **3개의 게이트(Gate)**를 통해 이 흐름을 정교하게 제어합니다.\n",
    "    - Forget Gate: 과거 정보 중 무엇을 잊어버릴지 결정합니다.\n",
    "    - Input Gate: 현재 입력 정보 중 무엇을 셀 상태에 저장할지 결정합니다.\n",
    "    - Output Gate: 셀 상태 정보 중 무엇을 다음 시점으로 출력할지 결정합니다.\n",
    "        - 주요 사용 사례: 자연어 처리(번역, 챗봇), 시계열 데이터 예측(주가, 날씨), 음성 인식 등 순서와 맥락이 중요한 모든 분야에서 강력한 성능을 발휘합니다.\n",
    "\n",
    "6. 전이 학습 모델 (Transfer Learning Models)\n",
    "전이 학습은 대규모 데이터셋(주로 ImageNet)으로 미리 학습된 모델의 지식을 가져와 새로운 문제에 적용하는 강력한 기법입니다.\n",
    "\n",
    "- VGG16 / VGG19:\n",
    "\n",
    "    - 특징: 3x3의 작은 컨볼루션 필터를 반복적으로 쌓아 네트워크의 깊이를 깊게 만든 모델입니다. 구조가 매우 단순하고 직관적이어서 이해하고 수정하기 쉽습니다. 16/19는 모델의 깊이(가중치를 가진 레이어 수)를 의미합니다.\n",
    "    - 강점: 구조의 단순함 덕분에 다양한 문제에 대한 훌륭한 **기본 특징 추출기(baseline feature extractor)**로 널리 사용됩니다.\n",
    "\n",
    "\n",
    "- InceptionV3:\n",
    "\n",
    "  - 특징: **'인셉션 모듈(Inception Module)'**이라는 독특한 블록을 사용합니다. 이 모듈은 1x1, 3x3, 5x5 등 다양한 크기의 컨볼루션 필터를 병렬로 적용한 뒤 그 결과를 합칩니다.\n",
    "    - 강점: 네트워크가 스스로 이미지에서 어떤 크기의 특징을 보는 것이 가장 효과적인지 학습하게 하므로, 적은 파라미터로도 매우 높은 성능을 낼 수 있습니다. 연산 효율성이 뛰어납니다.\n",
    "      \n",
    "- Xception (Extreme Inception):\n",
    "\n",
    "    - 특징: 인셉션의 아이디어를 극단적으로 발전시킨 모델입니다. **'깊이별 분리 합성곱(Depthwise Separable Convolution)'**을 기반으로 합니다. 이는 공간적 특징(가로, 세로)과 채널 간 특징을 분리하여 학습하므로, 파라미터 수와 계산량을 획기적으로 줄입니다.\n",
    "    - 강점: VGG나 Inception보다 훨씬 적은 파라미터로 더 높은 성능을 달성하는, 매우 효율적인 아키텍처입니다.\n",
    "      \n",
    "- MobileNet:\n",
    "\n",
    "    - 특징: Xception처럼 '깊이별 분리 합성곱'을 핵심으로 사용하며, 이름에서 알 수 있듯이 모바일 및 임베디드 기기와 같이 컴퓨팅 자원이 제한된 환경을 위해 설계되었습니다.\n",
    "    - 강점: 모델의 크기가 매우 작고 추론 속도가 빠르면서도 준수한 성능을 유지합니다. 실시간 객체 탐지 등 속도가 중요한 애플리케이션에 적합합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7466a2",
   "metadata": {
    "papermill": {
     "duration": 0.004303,
     "end_time": "2025-06-12T06:22:59.193894",
     "exception": false,
     "start_time": "2025-06-12T06:22:59.189591",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### 블록 4 데이터 증강 다중 입력 제너레이터. Data Augmentation & Generator for Multiple Inputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3b3c42a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T06:22:59.203666Z",
     "iopub.status.busy": "2025-06-12T06:22:59.203219Z",
     "iopub.status.idle": "2025-06-12T06:22:59.208439Z",
     "shell.execute_reply": "2025-06-12T06:22:59.207880Z"
    },
    "papermill": {
     "duration": 0.011227,
     "end_time": "2025-06-12T06:22:59.209433",
     "exception": false,
     "start_time": "2025-06-12T06:22:59.198206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data Augmentation을 위한 ImageDataGenerator 객체 생성\n",
    "\n",
    "batch_size = 64\n",
    "gen = ImageDataGenerator(horizontal_flip = True,\n",
    "                        vertical_flip = True,\n",
    "                        zoom_range = 0.2,\n",
    "                        rotation_range=10)\n",
    "\n",
    "# 두 개의 입력(이밎, 각도)를 받는 모델을 위한 커스텀 제너레이터 함수\n",
    "def gen_flow_for_two_inputs(X1, X2, y):\n",
    "    genX1 = gen.flow(X1, y, batch_size = batch_size, seed = 55)\n",
    "    genX2 = gen.flow(X1, X2, batch_size = batch_size, seed= 55) # 여기서 X1은 임시, X2가 실제 사용됨\n",
    "    while True:\n",
    "        #next는 이제 메소드가 아니라, 함수로 사용\n",
    "        X1i = next(genX1)\n",
    "        X2i = next(genX2)\n",
    "        yield (X1i[0], X2i[1]), X1i[1]\n",
    "\n",
    "# 모델 훈련 중 사용할 콜백 함수들을 정의하는 함수\n",
    "def get_callbacks(filepath, patience = 2):\n",
    "    es = EarlyStopping('val_loss', patience = 10, mode = 'min')\n",
    "    msave = ModelCheckpoint(filepath, save_best_only = True)\n",
    "    return [es, msave]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b40d77",
   "metadata": {
    "papermill": {
     "duration": 0.004282,
     "end_time": "2025-06-12T06:22:59.218080",
     "exception": false,
     "start_time": "2025-06-12T06:22:59.213798",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### 상세 설명:\n",
    "이 블록은 모델의 일반화 성능을 높이기 위한, 데이터 증강을 설정!\n",
    "\n",
    "1. `ImageDataGenerator` : Keras에서 제공하는 데이터 증강 도구. 기존 이미지에 좌우/상하 반전, 확대/축소, 회전 등 미세한 변화를 무작위로 적용하여, 마치 새로운 데이터인 것처럼 훈련 데이터를 늘려주는 효과. `ImageDataGenerator`를 통해, 이미지 변경 객체를 생성.\n",
    "\n",
    "2. `gen_flow_for_two_inputs` 함수 : 이 코드의 학샘 중 하나. 우리가 만들 모델은 두 종류의 입력, 즉 이미지 데이터(X1)과 각도 데이터 (X2)를 동시에 받습니다. 하지만, Keras의 기본 제너레이터는 보통 하나의 입력 X와 하나의 출력 y만 처리합니다. 이 함수는 이 문제를 해결하기 위해, 만들어진 커스텀 제너레이터입니다!\n",
    "    - seed = 55 : genX1과 genX2에 동일한 seed를 사용하는 것이 매우 중요합니다. 이렇게 해야 genX1에서 첫 번째 이미지를 회전시켰다면, genX2에서도 첫 번째 이미지에 해당하는 각도 데이터가 정확히 같은 쌍으로 묶여서 나옵니다. 즉, 데이터의 짝이 어긋나지 않게 해줍니다.\n",
    "  \n",
    "    - yiled [X1i[0], X2i[1]], X1i[1] : 이 부분이 실제로 모델에 데이터를 전달하는 부분. 한 번에 batch_size 만큼의 데이터를 생성하며, 입력은 [이미지 배치, 각도 배치] 형태의 리스트이고, 출력은 정답 레이블 배치입니다!\n",
    "  \n",
    "    - 좀 더 구체적인 설명 :\n",
    "  \n",
    "        1. `get.flow(X1,y, ...)` 에서 y를 인자로 받는 이유\n",
    "        - 결론 : 증강된 이미지 X1와 그 짝이 되는 정답 y의 연결고리를 절대 놓치지 않기 위해서.\n",
    "        - 모델은 (입력, 정답) 쌍을 보고 학습합니다. 즉, '이런 이미지가 들어오면, 정답은 이것이다'라는 관계를 배우는 것.\n",
    "        - `ImageDataGenerator`는 다음과 같은 일을 합니다.\n",
    "            1. 원본 이미지 데이터 X1를 가져옵니다.\n",
    "            2. 무작위로 뒤섞습니다. Shuffle\n",
    "            3. 무작위로 변형 augmentation을 가합니다\n",
    "        - 만약 X1만 gen.flow에 넘겨준다면, 제너레이터는 이미지를 뒤섞고 변형한 뒤 새로운 순서의 이미지 배치를 만들어낼 겁니다. 하지만, 우리는 새로운 순서에 맞는 정답 y의 순서를 알 수 없게됩니다. 원래 5번 인덱스에 있던 '빙산'의 이미지가 무작위 회전 후 섞여서 23번 인덱스가 되었는데, 정작 23번 인덱스의 정답은 엉뚱한 '배'가 될 수 있는 것이죠.\n",
    "        - gen.flow(X1,y)는 이 문제를 완벽하게 해결합니다.\n",
    "        - flow 메서드에 X1와 y를 함께 넘겨주면, 제너레이터는 내부적으로 X1과 y를 한쌍으로 묶어서 관리합니다. 그래서, X1의 순서를 섞을 때, y의 순서도 정확히 동일하게 섞어줍니다. X1의 5번 이미지를 10도 회전시켜 배치에 포함시킬 때, y의 5번 정답을 함께 가져와 그 이미지의 짝으로 붙여줍니다.\n",
    "        2. batch_size 설명\n",
    "        - batch_size란, 모델이 가중치를 한 번 업데이트하기 위해, 학습하는 데이터 샘플의 개수를 의미합니다.\n",
    "     \n",
    "        - 딥러닝 모델은 수많은 데이터를 보고 학습하지만, 전체 데이터를 한 번에 보고 학습하는 경우는 거의 없습니다! 대신, 데이터를 작은 묶음(mini-batch)으로 나누어 학습을 진행합니다.\n",
    "     \n",
    "            - batch_size = 1 : Stochastic Gradeint Descent : 데이터 1개를 보고, 오차를 계산한 뒤, 즉시 가중치를 업데이트. 학습 과정이 매우 불안정하고 들쭉날쭉합니다.\n",
    "            - batch_size = 전체 데이터 개수 : Batch Gradient Descent : 전체 데이터를 모두 보고, 모든 오차의 평균을 계산한 뒤, 가중치를 딱 한 번 업데이트합니다. 학습 과정이 매우 안정적이지만, 메모리 요구량이 엄청나고 계산에 시간이 너무 오래 걸립니다.\n",
    "            - batch_size = 32, 64, 128...(Mini-batch Gradient Descent) : 위 두 방법의 절충안.\n",
    "                1. 메모리 효율성 : 전체 데이터를 메모리에 올릴 필요 없이, 배치 크기만큼의 데이터만 있으면 되므로 효율적.\n",
    "                2. 계산 효율성 : GPU는 여러 계산을 병렬로 처리하는 데 특화. 데이터 1개를 64번 처리하는 것보다, 64개를 한 묶음으로 처리하는 것이 훨씬 빠릅니다!\n",
    "                3. 안정적인 학습. : 1개의 데이터는 노이즈가 심할 수 있지만, 32개 데이터의 평균 오차는 전체 데이터의 경향성을 더욱 안정적으로 대표!\n",
    "        \n",
    "        3. Flow 메서드\n",
    "        - 역할 : 이미 메모리에 불러와 있는 NumPy 배열 형태의 데이터를 입력 받아, 실시간으로 데이터 증강을 적용하고 지정된 batch_size만큼의 데이터를 계속해서 만들어내는 제너레이터 객체를 생성.\n",
    "        - 작동과정 :\n",
    "            1. X 이미지 데이터와 y 정답 데이터를 입력으로 받음\n",
    "            2. 내부적으로 ImageDataGenerator에서 정의된 증강 규칙과 배치 크기를 기억\n",
    "            3. model.fit()이 제너레이터에게 데이터를 요청하면, flow는 다음 작읍을 수행\n",
    "                - 전체 데이터 (X, y) 중에서 batch_size만큼의 데이터를 무작위로 샘플링.\n",
    "                - 샘플링된 이미지X에 증강 규칙을 적용하여 새로운 이미지 형성\n",
    "                - 증강된 이미지와 그에 해당하는 정답 y를 한 쌍으로 묶어 (배치 이미지, 배치 정답) 형태로 반환 yield합니다.\n",
    "                - return vs yield\n",
    "                    - return :  함수 내에서 return을 만나면, 함수는 값을 반환하고 완전히 종료됨. 함수 내의 모든 지역 변수와 상태는 사라짐.\n",
    "                    - yield : 함수 내에서 yield를 만나면, 함수는 값을 반환하고, 그 자리에서 실행을 일시 정지. 함수 내의 모든 지역 변수와 상태는 그대로 보존. 다음에 이 함수가 다시 호출되면, 멈췄던 그 다음 줄부터 실행을 재개.\n",
    "            4. model.fit()은 이 데이터를 받아 학습하고, 다시 제너레이터에게 다음 배치를 요청. 이 과정이 steps_per_epoch만큼 반복.\n",
    "  \n",
    "3. get_callbacks 함수 : 훈련 중에 특정 조건이 만족되면 호출되는 함수들(콜백)을 설정\n",
    "\n",
    "    - earlystopping : 검증 손실 val_loss이 patience = 10 에포크 동안 개선되지 않으면 훈련을 자동으로 중단시켜 시간 낭비와 과적합을 방지.\n",
    "    - ModelCheckPoint : 검증 손실이 이전보다 낮아질 때만, save_best_only = True 모델의 가중치를 파일 filepath에 저장\n",
    "\n",
    "\n",
    "Q. 왜 yield가 딥러닝에서 필수적인가?\n",
    "- 메모리 효율성 때문입니다.\n",
    "수십만 장의 이미지 데이터를 증강한다고 생각해 보세요. 만약 return을 사용한다면, 증강된 이미지 수십만 장을 모두 메모리에 만들어 올린 뒤 반환해야 합니다. 이는 엄청난 메모리 낭비이며, 데이터가 크면 아예 불가능합니다.\n",
    "\n",
    "- 하지만 yield를 사용하는 제너레이터는 다릅니다.\n",
    "model.fit()이 데이터 한 배치를 요청하면, 제너레이터는 정확히 한 배치 분량의 데이터만 만들어서 yield로 전달합니다. 모델이 그 배치로 학습하는 동안 제너레이터는 잠시 쉬고 있습니다. 학습이 끝나고 모델이 다음 배치를 요청하면, 제너레이터는 다시 깨어나 다음 한 배치만 만들어서 전달합니다.\n",
    "\n",
    "- 즉, 아무리 큰 데이터셋이라도 메모리에는 항상 딱 한 배치 크기만큼의 데이터만 올라와 있게 됩니다. while True: 루프와 yield의 조합은 이 과정을 무한히 반복하며, fit 메서드에 마르지 않는 데이터의 샘을 제공하는 것과 같습니다. 이것이 바로 Keras 제너레이터가 효율적으로 동작하는 핵심 원리입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2851d2",
   "metadata": {
    "papermill": {
     "duration": 0.004195,
     "end_time": "2025-06-12T06:22:59.226579",
     "exception": false,
     "start_time": "2025-06-12T06:22:59.222384",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### 블록 5 다중 입력 VGG16 모델 정의 Defining the Multi-input VGG16 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26ad7149",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T06:22:59.236220Z",
     "iopub.status.busy": "2025-06-12T06:22:59.236008Z",
     "iopub.status.idle": "2025-06-12T06:22:59.242160Z",
     "shell.execute_reply": "2025-06-12T06:22:59.241637Z"
    },
    "papermill": {
     "duration": 0.012217,
     "end_time": "2025-06-12T06:22:59.243108",
     "exception": false,
     "start_time": "2025-06-12T06:22:59.230891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf # 혹은 from keras.optimizers import schedules\n",
    "\n",
    "def getVggAngleModel():\n",
    "    # 두 번째 입력 : 각도 데이터 (1개의 값을 가짐)\n",
    "    input_2 = Input(shape=[1], name = 'angle')\n",
    "    # 각도 입력을 위한 간단한 Dense 레이어\n",
    "    angle_layer = Dense(1)(input_2)\n",
    "\n",
    "    # 기본 모델 : VGG 16 (ImageNet 가중치 사용, 상위 분류층은 제외)\n",
    "    base_model = VGG16(weights = 'imagenet', include_top = False,\n",
    "                      input_shape = X_train.shape[1:], classes = 1)\n",
    "\n",
    "    # VGG 16의 block5_pool 레이어의 출력을 가져옴\n",
    "    x = base_model.get_layer('block5_pool').output\n",
    "\n",
    "    # 이미지 특징을 1차원 벡터로 변환\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "\n",
    "    # 이미지 특징 벡터와 각도 특징 벡터를 결합 (concatenate)\n",
    "    merge_one = concatenate([x, angle_layer])\n",
    "\n",
    "    # 결합된 특징을 기반으로 새로운 분류층을 쌓음\n",
    "    merge_one = Dense(512, activation = 'relu', name = 'fc2')(merge_one)\n",
    "    merge_one = Dropout(0.3)(merge_one)\n",
    "    merge_one = Dense(512, activation = 'relu', name = 'fc3')(merge_one)\n",
    "    merge_one = Dropout(0.3)(merge_one)\n",
    "\n",
    "    # 최종 예측 : 1개의 노드와 sigmoid 활성화 함수를 사용한 이진 분류\n",
    "    predictions = Dense(1, activation = 'sigmoid')(merge_one)\n",
    "\n",
    "    # 최종 모델 정의 : 입력은 2개 (이미지, 각도), 출력은 predictions\n",
    "    model = Model(inputs = [base_model.input, input_2], outputs = predictions)\n",
    "\n",
    "    # 학습률 스케줄러 정의\n",
    "    # 초기 학습률 0.001에서 시작하여, 10000 스텝마다 0.9배씩 학습률을 감소시킴\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=1e-3,\n",
    "        decay_steps=10000,\n",
    "        decay_rate=0.9\n",
    "    )\n",
    "\n",
    "    # 스케줄러를 learning_rate 파라미터에 직접 전달\n",
    "    sgd = SGD(learning_rate=lr_schedule, momentum=0.9, nesterov=True)\n",
    "    \n",
    "    # 모델 컴파일 : 손실함수, 옵티 마이저, 평가 지표 설정\n",
    "    #sgd = SGD(learning_rate=1e-3, momentum = 0.9, nesterov = True)\n",
    "    model.compile(loss = 'binary_crossentropy',\n",
    "                 optimizer = sgd,\n",
    "                 metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab2a400",
   "metadata": {
    "papermill": {
     "duration": 0.004184,
     "end_time": "2025-06-12T06:22:59.251629",
     "exception": false,
     "start_time": "2025-06-12T06:22:59.247445",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 상세 설명 :\n",
    "- 이 함수는 전이학습과 다중 입력을 결합한 강력한 모델을 구축!\n",
    "\n",
    "모델 설계 철학 : 왜 이 구조를 사용하는가?\n",
    "이 모델의 핵심 목표는 두 종류의 다른 정보, 즉 위성 이미지(band_1, band_2)와 입사각(inc_angle)을 모두 활용하여 빙산을 탐지하는 것.\n",
    "\n",
    "- 이미지 정보 : 객체의 형태, 질감 등 시각적 특징을 담고 있음.\n",
    "- 각도 정보 : 이미지가 어떤 각도에서 촬영되었는 지를 나타내는 수치 데이터로, 이미지 해석에 중요한 추가 단서.\n",
    "\n",
    "이처럼 성격이 다른 두 데이터를 효과적으로 결합하기 위해, Keras의 Sequential API가 아닌, 더 유연하고 강력한 Functional API를 사용. 이를 통해, 각 데이터를 별도의 경로로 처리한 뒤, 중간에 하나로 합치는 '두 갈래(two-stream)' 구조의 모델 설계를 할 수 있음.\n",
    "\n",
    "---\n",
    "코드 라인별 상세 설명\n",
    "\n",
    "### 1단계 : 입력 정의\n",
    "\n",
    "```\n",
    "# 두 번째 입력: 각도 데이터 (1개의 값을 가짐)\n",
    "input_2 = Input(shape=[1], name='angle') # shape=[1] 1차원의 값을 가짐\n",
    "# 각도 입력을 위한 간단한 Dense 레이어\n",
    "angle_layer = Dense(1)(input_2)\n",
    "```\n",
    "\n",
    "- `input_2 = Input(shape=[1], name = 'angle')`:\n",
    "    - `Input` : Funtional API에서 모델의 입력 지점을 선언하는 레이어. (Input Layer) \"여기서 데이터가 들어온다\"라고 알려주는 문과 같음.\n",
    "    - `shape=[1]` : 입력될 데이터의 형태를 정의합니다. inc_angle은 단일 숫자 값이므로, `[1]` 즉, 1개의 원소를 가진 벡터 형태임을 명시합니다.\n",
    "    - Q. 왜 '[1]'로 정의할까? 각도의 데이터는 (샘플수x75x75)가 아닌가?\n",
    "    - `name='angle'` : 입력의 이름을 'angle'로 지정. 모델 구조를 시각화하거나 나중에 특정 레이어를 참조할 때, 가독성과 편의성을 높여줌.\n",
    "- `angle_layer = Dense(1)(input_2)`:\n",
    "    - 이 부분이 매우 중요. input_2를 바로 사용하지 않고, 왜 Dense(1) 레이어를 통과시킬까?\n",
    "    - 역할 : 이는 각도 데이터에 대한 **학습 가능한 가중치 weight와 편향 bias**를 만들어주는 역할을 함. 즉, 모델이 '이 각도 값에 얼마만큼의 중요도(가중치)'를 부여할지를 스스로 학습하게 됨. 단순히 원시 (raw) 데이터를 사용하는 것보다 모델에 더 큰 유연성을 부여하며, 각도 정보를 더 의미 있는 특징으로 변환하는 과정.\n",
    "    - Q. 여기서 Dense(1)에서 1이 의미하는 건 무엇인가? 각각의 각도에 가중치를 준다면, (75x75)픽셀 전부에 가중치를 준다는 것인가?\n",
    "\n",
    "### 2단계 : 특징 추출기 정의 (Defining the Feature Extractor)\n",
    "```\n",
    "# 기본 모델 : VGG16 (ImageNet 가중치 사용, 상위 분류층은 제외)\n",
    "base_model = VGG16(weights = 'imagenet', include_top = False,\n",
    "                    input_shape=X.train.shape[1:], classes=1)\n",
    "\n",
    "#VGG16의 'black5_poop' 레이어의 출력을 가져옴\n",
    "x = base_model.get_layer('block5_pool').output\n",
    "```\n",
    "\n",
    "- `base_model = VGG16(,,,)`:\n",
    "    - `weights = 'imagenet'`: 우리는 VGG16 모델을 밑바닥부터 훈련시키는 것이 아니다! 수백만 장의 다양한 이미지가 담긴 'imagenet' 데이터셋으로 이미 훈련이 사전에 완료된, 사전 학습된 가중치를 그대로 사용하겠다는 의미! 이것이 바로 전이 학습의 핵심!\n",
    "    - `include_top` = False : imageNet은 1000개의 클래스를 분류하는 문제였다. `top`은 바로 이 1000개를 분류하기 위한 마지막 완전 연결 계층 fully connected Layers를 의미함. 우리는 1000개 분류가 아닌 빙산/배 분류를 할 것이므로, 이 '머리' 부분은 필요 없음.\n",
    "      `include_top = Flase`는 이 머리 부분을 잘라내고, 이미지의 보편적인 특징(선, 면, 질감, 형태 등)을 추출하는 강력한 '몸통' 부분만 사용하겠다는 의미.\n",
    "    - input_shape = X_train.shape[1:] : 우리가 사용할 이미지의 크기 (높이, 너비, 채널 수)를 모델에게 알려줍니다. VGG16의 몸통 부분이 이 형태에 맞춰 구성됩니다.\n",
    "    - Q. 여기에서 X_train.shape[1:]는 어떤 쉐입인가?\n",
    " - `x = base_model.get_layer('block5_pool').output` :\n",
    "     - VGG16 모델의 여러 레이어 중에서, 이름이 `block5_pool`인 레이어를 찾아, 그 출력 텐서를 `x`에 저장. 이는 VGG16의 몸통 부분 중에서도 가장 깊은 곳에서 나오는, 고차원적이고 압축된 특징 정보를 사용하겠다는 의미.\n",
    "\n",
    "### 3단계 : 특징 벡터화 및 결합 Feature Vectorization & Merging\n",
    "```\n",
    "# 이미지 특징을 1차원 벡터로 변환\n",
    "x = GlobalMaxPooling2D()(x)\n",
    "\n",
    "# 이미지 특징 벡터와 각도 특징 벡터를 결합 (concatenate)\n",
    "merge_one = concatenate([x, angle_layer])\n",
    "```\n",
    "\n",
    "- `x = GlobalMaxPooling2D()(x)`:\n",
    "    - `block5_pool`의 출력은 아직 2차원의 공간 정보를 가진 특징 맵 형태 (e.g., 4 x 4 x 512). 이를 분류기에 넣기 위해 1차원 벡터로 만들어야 합니다. GlobalMaxPooling2D는 각 채널 512개에서 가장 중요한 특징 값 하나만을 뽑아, (512, )크기의 1차원 벡터로 변환. 이는 과적합을 줄이면서도 핵심 특징을 효과적으로 요약.\n",
    "\n",
    "- `merge_one = concatenate([x, angle_layer])` :\n",
    "    - 이 모델의 심장부. 두 갈래로 들어온 정보가 여기에서 하나로 합쳐집니다!\n",
    "    - 이미지로부터 추출된 특징 벡터 x(크기 512)와, 각도 정보로부터 변환된 특징 벡터 angler_layer (크기 1)을 이어 붙여, 총 (513,) 크기의 새로운 통합 특징 벡터를 만듭니다. 이제 모델은 이 통합된 정보를 바탕을 최종 판단을 내릴 준비를 합니다.\n",
    "\n",
    "### 4단계 : 맞춤형 분류기 구축 Building the Custom Classifier\n",
    "```\n",
    "# 결합된 특징을 기반으로 새로운 분류층을 쌓음.\n",
    "merge_one = Dense(512, activation = 'relu', name = 'fc3')(merge_on)\n",
    "merge_one = Dropout(0.3)(merge_one)\n",
    "merge_one = Dense(512, activation = 'relu', name = 'fc3')(merge_on)\n",
    "merge_one = Dropout(0.3)(merge_one)\n",
    "\n",
    "# 최종 예측 : 1개의 노드와 sigmoid 활성화 함수를 사용한 이진 분류\n",
    "predictions = Dense(1, activation = 'sigmoid')(merge_one) \n",
    "```\n",
    "\n",
    "- Dense와 Dropout 층들:\n",
    "\n",
    "    - 이 부분은 include_top=False로 잘라냈던 '머리' 부분을 우리 문제에 맞게 새로 만들어 붙이는 과정입니다.\n",
    "    - Dense(512, activation='relu'): 513개의 통합 특징을 입력받아 512개의 뉴런으로 더 복잡한 패턴을 학습합니다.\n",
    "    - Dropout(0.3): 훈련 시 30%의 뉴런을 무작위로 비활성화하여, 모델이 특정 특징에만 과도하게 의존하는 것을 막고 과적합을 방지합니다.\n",
    "참고: 코드에서 name='fc2'가 두 번 사용되었는데, 두 번째는 name='fc3'로 하는 것이 일반적인 관례입니다.\n",
    "- `predictions = Dense(1, activation='sigmoid'):`\n",
    "    - 최종 출력 레이어입니다.\n",
    "    - Dense(1): '빙산이다 / 아니다' 라는 이진 분류(binary classification) 문제이므로, 최종 출력 뉴런은 1개입니다.\n",
    "    - activation='sigmoid': Sigmoid 함수는 어떤 입력값이든 0과 1 사이의 값으로 변환해 줍니다. 이 출력값은 '이미지가 빙산일 확률'로 해석될 수 있습니다. (e.g., 0.9는 빙산일 확률이 90%임을 의미)\n",
    "\n",
    "### 5단계 : 모델 정의 및 컴파일 Model Definition & Compilation\n",
    "```\n",
    "# 최종 모델 정의: 입력은 2개(이미지, 각도), 출력은 predictions\n",
    "model = Model(inputs=[base_model.input, input_2], outputs=predictions)\n",
    "\n",
    "# 모델 컴파일: 손실 함수, 옵티마이저, 평가 지표 설정\n",
    "sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "return model\n",
    "```\n",
    "- model = Model(...):\n",
    "\n",
    "    - Functional API를 사용하여 최종 모델의 청사진을 완성합니다. \"이 모델은 base_model.input(이미지)과 input_2(각도)라는 두 개의 입력을 받아서, 복잡한 내부 경로를 거친 뒤 predictions라는 하나의 출력을 내보낸다\"고 명확히 정의합니다.\n",
    "- model.compile(...):\n",
    "    - 만들어진 모델을 훈련할 수 있도록 '설정'하는 과정입니다.\n",
    "    - loss='binary_crossentropy': 이진 분류 문제에서 확률 기반 예측(sigmoid)의 오차를 측정하는 가장 표준적인 손실 함수입니다.\n",
    "    - optimizer=sgd: 앞서 설정한 SGD 옵티마이저를 사용하여 손실을 최소화하도록 가중치를 업데이트합니다.\n",
    "    - metrics=['accuracy']: 훈련 과정에서 손실과 더불어 '정확도'도 함께 기록하고 모니터링합니다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Q. Functional API이란?\n",
    "\n",
    "1. Keras의 Functional API\n",
    "Functional API는 Keras에서 신경망 모델을 만드는 두 가지 방법 중 하나로, Sequential API보다 훨씬 유연하고 강력한 방식입니다.\n",
    "\n",
    "- Sequential API가 마치 레고 블록을 순서대로 차곡차곡 쌓아 올리는 것처럼 단순한 모델을 만드는 데 적합하다면, Functional API는 레이어를 함수처럼 다루어 복잡한 그래프(Graph) 구조를 만들 수 있게 해줍니다.\n",
    "\n",
    "- 핵심 아이디어\n",
    "    - 레이어를 하나의 함수라고 생각하는 것입니다. output_tensor = MyLayer()(input_tensor) 처럼, 입력 텐서(데이터)를 레이어 함수에 통과시켜 출력 텐서를 얻습니다. 이 과정을 자유롭게 연결하여 모델의 데이터 흐름을 직접 설계합니다.\n",
    "\n",
    "- Functional API가 꼭 필요한 경우 (장점)\n",
    "    - Sequential API로는 구현이 불가능하거나 매우 어려운, 다음과 같은 복잡한 모델을 만들 수 있습니다.\n",
    "\n",
    "- 다중 입력 (Multi-input) 및 다중 출력 (Multi-output) 모델:\n",
    "\n",
    "    - 이번에 분석한 getVggAngleModel처럼 이미지와 각도라는 두 개의 다른 입력을 받는 모델이 대표적인 예입니다.\n",
    "    - 하나의 입력으로 여러 가지를 동시에 예측하는 모델(e.g., 이미지 한 장으로 객체의 종류와 위치를 모두 예측)도 만들 수 있습니다.\n",
    "- 레이어 공유 (Shared Layers):\n",
    "\n",
    "    - 하나의 레이어 인스턴스를 여러 입력에 재사용하여 가중치를 공유하는 모델을 만들 수 있습니다. 예를 들어, 두 문장의 유사도를 비교할 때 동일한 임베딩 레이어를 사용하는 경우가 있습니다.\n",
    "- 비선형적 토폴로지 (Non-linear Topology):\n",
    "\n",
    "    - 데이터의 흐름이 중간에 여러 갈래로 나뉘었다가 다시 합쳐지는 Inception 모델이나, 잔차 연결(residual connection)이 있는 ResNet 같은 복잡한 구조를 구현할 수 있습니다.\n",
    "\n",
    "- 결론적으로, Functional API는 딥러닝 아키텍처를 훨씬 더 자유롭게 설계할 수 있게 해주는 전문가용 도구라고 할 수 있습니다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "[입력 1: 이미지]         [입력 2: 각도]\n",
    "      |                       |\n",
    "      ▼                       ▼\n",
    "[VGG16의 '눈']        [Dense(1) 레이어]\n",
    "(특징 추출기)          (특징 변환기)\n",
    "      |                       |\n",
    "      ▼                       ▼\n",
    "[이미지 특징 벡터]      [각도 특징 벡터]\n",
    "(e.g., 512개 값)      (e.g., 1개 값)\n",
    "      |                       |\n",
    "      +-------(concatenate)-------+\n",
    "                  |\n",
    "                  ▼\n",
    "            [merge_one]\n",
    "         (통합 특징 벡터, 513개 값)\n",
    "                  |\n",
    "                  ▼\n",
    "        [우리만의 '새로운 두뇌']\n",
    "       (Dense + Dropout 레이어들)\n",
    "                  |\n",
    "                  ▼\n",
    "          [최종 예측 (확률)]\n",
    "```\n",
    "\n",
    "#### Question 1. 모델 구축의 워크플로우는 어떻게 되는가?\n",
    "<다중 입력 모델 설계 4단계 워크플로우>\n",
    "\n",
    "1. 1단계 (\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad2fe98",
   "metadata": {
    "papermill": {
     "duration": 0.004243,
     "end_time": "2025-06-12T06:22:59.260210",
     "exception": false,
     "start_time": "2025-06-12T06:22:59.255967",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. 복잡한 모델 구축 흐름, 정립하기\n",
    "복잡해 보이는 Functional API의 모델 구축 과정은 사실 매우 체계적인 4단계의 설계도를 따릅니다. 앞으로 어떤 복잡한 모델을 보시더라도 이 4단계 프레임워크에 대입해 보면 구조가 한눈에 들어올 겁니다.\n",
    "\n",
    "<다중 입력 모델 설계 4단계 워크플로우>\n",
    "\n",
    "1단계: 재료 준비 (입력 정의)\n",
    "목표: 우리 모델이 어떤 종류의 데이터를 받을지 모두 선언합니다.\n",
    "실행: Input() 레이어를 사용해 모델의 '입구'를 모두 만듭니다. 우리 모델은 이미지와 각도, 두 가지 재료가 필요하니 입구도 두 개를 만듭니다.\n",
    "image_input = Input(shape=[75, 75, 3])\n",
    "angle_input = Input(shape=[1])\n",
    "2단계: 재료별 손질 (개별 특징 추출)\n",
    "목표: 각 재료의 특성에 맞게 개별적으로 전처리하거나 특징을 추출합니다.\n",
    "실행: 각 입력에 맞는 '처리 공정'을 따로따로 설계합니다.\n",
    "이미지 공정: 이미지(image_input)는 VGG16이라는 강력한 '분쇄기'에 넣어 고차원적인 특징 벡터로 압축합니다.\n",
    "각도 공정: 각도(angle_input)는 Dense(1)이라는 간단한 '변환기'를 통과시켜 모델이 사용하기 좋은 특징으로 만듭니다.\n",
    "3단계: 재료 혼합 (특징 결합)\n",
    "목표: 각자 손질된 재료들을 하나의 그릇에 담아 합칩니다.\n",
    "실행: concatenate 레이어를 사용해 각 공정에서 나온 특징 벡터들을 하나로 이어 붙입니다.\n",
    "merged_features = concatenate([image_features, angle_features])\n",
    "이 merged_features가 바로 merge_one입니다. 이제 여기에는 이미지 정보와 각도 정보가 모두 담겨 있습니다.\n",
    "4단계: 최종 조리 (예측)\n",
    "목표: 잘 섞인 재료를 오븐에 넣고 구워 최종 결과물을 만듭니다.\n",
    "실행: 합쳐진 merged_features를 입력으로 받아, 우리 문제에 특화된 완전 연결 신경망(Dense 레이어들)을 통과시켜 최종 예측 확률을 출력합니다.\n",
    "이 4단계, 정의 → 추출 → 결합 → 예측 흐름을 기억하시면, 앞으로 어떤 복잡한 모델을 보더라도 길을 잃지 않고 그 구조를 분석하실 수 있을 겁니다.\n",
    "\n",
    "2. Functional API의 () () 작동 방식\n",
    "이 부분은 파이썬의 객체 지향 프로그래밍과 Keras의 설계 철학이 결합된 결과입니다. 아주 좋은 질문이에요.\n",
    "\n",
    "결론부터 말하면, 첫 번째 괄호 ()는 '레이어 객체 생성 및 설정'이고, 두 번째 괄호 ()는 '해당 레이어에 입력 데이터를 통과시키는 실행'입니다.\n",
    "\n",
    "비유: '기계'를 만들고 '작동'시키기\n",
    "Dense(512, activation='relu')와 같은 코드를 '기계'에 비유해 보겠습니다.\n",
    "\n",
    "Dense(512, activation='relu'): 이 부분은 기계를 만드는 과정입니다.\n",
    "\n",
    "Dense라는 종류의 기계를 만들기로 결정하고, 첫 번째 괄호 () 안에 기계의 설정을 지정합니다. \"뉴런은 512개짜리로 하고, 활성화 함수는 'relu' 다이얼에 맞춰줘.\"\n",
    "이 코드가 실행된 시점에서, 설정이 완료된 Dense 기계 **한 대(객체)**가 메모리에 만들어졌지만, 아직 아무 일도 하지 않고 그냥 서 있는 상태입니다.\n",
    "(...) (merge_one): 이 두 번째 괄호가 바로 기계를 작동시키는 스위치입니다.\n",
    "\n",
    "\"자, 이제 방금 만든 그 Dense 기계에 merge_one이라는 재료를 넣고 작동시켜!\" 라는 의미입니다.\n",
    "기계는 merge_one을 입력으로 받아 내부 계산을 수행한 뒤, 그 결과물(출력 텐서)을 뱉어냅니다.\n",
    "이것을 코드로 풀어쓰면 다음과 같습니다.\n",
    "\n",
    "Python\n",
    "\n",
    "# 1. 기계를 먼저 만들고 설정합니다.\n",
    "my_dense_layer = Dense(512, activation='relu', name='fc3')\n",
    "\n",
    "# 2. 만들어진 기계에 데이터를 넣어 작동시키고, 그 결과를 받습니다.\n",
    "output = my_dense_layer(merge_one) \n",
    "Keras에서는 편의를 위해 이 두 줄의 코드를 한 줄로 합쳐서 output = Dense(512, ...)(merge_one) 처럼 쓸 수 있게 해주는 것입니다. GlobalMaxPooling2D()(x) 도 마찬가지 원리입니다. 'GlobalMaxPooling2D 기계'를 만들자마자, 바로 x를 넣어 작동시키는 것이죠.\n",
    "\n",
    "\"원래 존재하는 merge_one에 add.Dense() 하는 것이라고 이해해도 되는거야?\"\n",
    "\n",
    "이 부분이 정말 중요한 포인트입니다. 그렇게 이해하시면 안 됩니다. Functional API는 데이터의 흐름을 정의하는 방식입니다. Dense(...)(merge_one)은 merge_one이라는 텐서를 수정하는 것이 아니라, merge_one이 Dense 레이어를 통과하여 나온 새로운 출력 텐서를 만드는 것입니다. 우리는 이 새로운 출력 텐서를 다음 레이어의 입력으로 계속 연결해 나가는 것입니다.\n",
    "\n",
    "3. shape=[1]과 배치(Batch)의 비밀\n",
    "이것도 정말 많은 분들이 헷갈려 하는 부분입니다. 명확하게 정리해 드릴게요.\n",
    "\n",
    "핵심 규칙: Input 레이어를 정의할 때는, 데이터 '한 개'의 모양(shape)만 알려주면 됩니다. Keras는 배치(batch) 차원을 자동으로 처리해 줍니다.\n",
    "\n",
    "shape=[1]의 진짜 의미\n",
    "inc_angle 데이터 하나는 39.24 와 같은 단일 숫자입니다. 이 숫자 하나를 벡터로 표현하면 [39.24] 가 되고, 이 벡터의 모양은 (1,) 입니다. 즉, 1개의 원소를 가진 벡터라는 의미죠.\n",
    "\n",
    "shape=[1]은 바로 \"이 입구(Input)로는 데이터 샘플 하나가 들어올 때 (1,) 모양을 가질 거야\" 라고 모델에게 알려주는 것입니다. 만약 75x75 RGB 이미지라면 shape=[75, 75, 3] 이라고 알려주는 것과 같습니다.\n",
    "\n",
    "\"나는 배치를 통째로 넣는 줄 알았는데.\"\n",
    "네, 실제로 모델을 훈련시킬 때는 batch_size만큼의 데이터를 통째로 넣는 것이 맞습니다. 여기서 마법이 일어납니다.\n",
    "\n",
    "우리가 shape=[1]로 입력을 정의하면, Keras는 내부적으로 이 입력의 전체 모양을 (None, 1) 로 간주합니다.\n",
    "\n",
    "None: 이 부분이 바로 **배치 크기를 위한 자리(placeholder)**입니다. None은 \"여기는 어떤 숫자든 올 수 있다\"는 의미입니다. 훈련 시 batch_size가 32이면 (32, 1) 크기의 데이터가 들어오고, 64이면 (64, 1) 크기의 데이터가 들어오는 것을 알아서 처리해 줍니다.\n",
    "1: 이 부분이 우리가 정의한 데이터 샘플 하나의 모양입니다.\n",
    "비유: Input 레이어는 **'USB 포트'**를 설계하는 것과 같습니다. 우리는 'USB 메모리 스틱 한 개'가 들어갈 수 있도록 포트의 규격(shape=[1])을 설계합니다. 이 포트를 설계할 때 \"32개짜리 USB 상자가 들어올 거야\"라고 가정하지 않습니다. 하지만 일단 포트가 만들어지면, 32개짜리 상자에서 스틱을 가져오든 64개짜리 상자에서 가져오든 문제없이 데이터를 처리할 수 있습니다. None이 바로 이 유연성을 부여하는 것입니다.\n",
    "\n",
    "마지막 질문에 대한 답변\n",
    "\"뉴럴 네트워크에서는 Input도, 하나의 레이어로 보는거야?\"\n",
    "\n",
    "네, 맞습니다. Input은 실제 계산을 하지는 않지만, 모델의 입력을 정의하고 데이터의 shape과 dtype을 알려주는 역할을 하는 특별한 종류의 레이어입니다. Functional API 모델은 반드시 이 Input 레이어로 시작합니다.\n",
    "\"Dense(1)(input_2)를 통해, 인풋 레이어 다음에 새로운 레이어를 붙여주는거고?\"\n",
    "\n",
    "네, 정확합니다! 데이터의 흐름을 정의하는 것입니다. \"데이터는 input_2라는 입구를 통해 들어와서, 곧바로 Dense(1)이라는 첫 번째 처리 공정으로 흘러 들어간다\"는 경로를 설계한 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4576530",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T06:22:59.269766Z",
     "iopub.status.busy": "2025-06-12T06:22:59.269571Z",
     "iopub.status.idle": "2025-06-12T06:22:59.276684Z",
     "shell.execute_reply": "2025-06-12T06:22:59.276222Z"
    },
    "papermill": {
     "duration": 0.013076,
     "end_time": "2025-06-12T06:22:59.277562",
     "exception": false,
     "start_time": "2025-06-12T06:22:59.264486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def myAngleCV(X_train, X_angle, X_test, target_train): # target_train을 인자로 받도록 수정\n",
    "    K = 3\n",
    "    # StratifiedKFold를 사용하여 데이터를 3개의 fold로 나눔\n",
    "    folds = list(StratifiedKFold(n_splits=K, shuffle=True, random_state=16).split(X_train, target_train))\n",
    "    \n",
    "    # 예측 결과를 저장할 배열 초기화\n",
    "    y_test_pred_log = 0\n",
    "    y_train_pred_log = 0\n",
    "    y_valid_pred_log = np.zeros_like(target_train, dtype='float32') # [수정] 더 명확한 배열 초기화\n",
    "\n",
    "    # 각 fold에 대해 훈련과 검증을 반복\n",
    "    for j, (train_idx, test_idx) in enumerate(folds):\n",
    "        print(f'\\n=================== FOLD {j+1}/{K} ===================') # [개선] f-string 사용\n",
    "        # 현재 fold에 맞는 훈련/검증 데이터 분리\n",
    "        X_train_cv, y_train_cv = X_train[train_idx], target_train[train_idx]\n",
    "        X_holdout, Y_holdout = X_train[test_idx], target_train[test_idx]\n",
    "        \n",
    "        # Angle 데이터도 동일하게 분리\n",
    "        X_angle_cv, X_angle_hold = X_angle[train_idx], X_angle[test_idx]\n",
    "\n",
    "        # 콜백을 위한 파일 경로 정의\n",
    "        file_path = f\"{j}_aug_model_weights.keras\" # [개선] f-string 및 .keras 확장자 사용 권장\n",
    "        callbacks = get_callbacks(filepath=file_path, patience=5)\n",
    "        \n",
    "        # 데이터 증강 제너레이터 생성\n",
    "        gen_flow = gen_flow_for_two_inputs(X_train_cv, X_angle_cv, y_train_cv)\n",
    "        \n",
    "        # 매번 새로운 모델 생성\n",
    "        galaxyModel = getVggAngleModel()\n",
    "        \n",
    "        # [가장 중요한 수정] fit_generator -> fit 으로 변경\n",
    "        galaxyModel.fit(\n",
    "            gen_flow,\n",
    "            steps_per_epoch=24,\n",
    "            epochs=100,\n",
    "            verbose=1,\n",
    "            validation_data=([X_holdout, X_angle_hold], Y_holdout),\n",
    "            callbacks=callbacks\n",
    "            # [수정] shuffle=True 인자 제거\n",
    "        )\n",
    "\n",
    "        # 훈련 후 최고 성능의 가중치를 다시 불러옴\n",
    "        galaxyModel.load_weights(filepath=file_path)\n",
    "        \n",
    "        # 훈련 및 검증 세트에 대한 성능 평가\n",
    "        score_train = galaxyModel.evaluate([X_train_cv, X_angle_cv], y_train_cv, verbose=0)\n",
    "        print(f'Fold {j+1} Train loss: {score_train[0]:.4f}, Train accuracy: {score_train[1]:.4f}')\n",
    "        score_valid = galaxyModel.evaluate([X_holdout, X_angle_hold], Y_holdout, verbose=0)\n",
    "        print(f'Fold {j+1} Test/Holdout loss: {score_valid[0]:.4f}, Test/Holdout accuracy: {score_valid[1]:.4f}')\n",
    "\n",
    "        # 검증 세트에 대한 예측 수행 (Out-of-Fold 예측)\n",
    "        pred_valid = galaxyModel.predict([X_holdout, X_angle_hold])\n",
    "        y_valid_pred_log[test_idx] = pred_valid.flatten() # [개선] .reshape 대신 .flatten() 사용\n",
    "\n",
    "        # 전체 테스트 세트에 대한 예측 수행 및 누적 (앙상블)\n",
    "        temp_test = galaxyModel.predict([X_test, X_test_angle])\n",
    "        y_test_pred_log += temp_test.flatten()\n",
    "\n",
    "        # (선택적) 전체 훈련 세트에 대한 예측 수행 및 누적\n",
    "        temp_train = galaxyModel.predict([X_train, X_angle])\n",
    "        y_train_pred_log += temp_train.flatten()\n",
    "\n",
    "    # K개의 모델이 예측한 결과의 평균을 최종 예측값으로 사용\n",
    "    y_test_pred_log = y_test_pred_log / K\n",
    "    y_train_pred_log = y_train_pred_log / K\n",
    "\n",
    "    print('\\n--- Final Cross-Validation Scores ---')\n",
    "    print(f'Overall Train Log Loss (In-Fold): {log_loss(target_train, y_train_pred_log):.4f}')\n",
    "    print(f'Overall Valid Log Loss (Out-of-Fold): {log_loss(target_train, y_valid_pred_log):.4f}')\n",
    "    \n",
    "    return y_test_pred_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3698cb1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T06:22:59.287326Z",
     "iopub.status.busy": "2025-06-12T06:22:59.286802Z",
     "iopub.status.idle": "2025-06-12T06:30:12.325434Z",
     "shell.execute_reply": "2025-06-12T06:30:12.324710Z"
    },
    "papermill": {
     "duration": 433.044602,
     "end_time": "2025-06-12T06:30:12.326553",
     "exception": false,
     "start_time": "2025-06-12T06:22:59.281951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================== FOLD 1/3 ===================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1749709380.441093      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "I0000 00:00:1749709380.441747      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1749709387.154005      65 service.cc:148] XLA service 0x7849bda0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1749709387.154851      65 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1749709387.154873      65 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1749709387.584114      65 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1749709399.188330      65 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 859ms/step - accuracy: 0.6019 - loss: 0.7866 - val_accuracy: 0.6430 - val_loss: 0.5559\n",
      "Epoch 2/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 221ms/step - accuracy: 0.7334 - loss: 0.4811 - val_accuracy: 0.8505 - val_loss: 0.3165\n",
      "Epoch 3/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 195ms/step - accuracy: 0.8144 - loss: 0.3708 - val_accuracy: 0.8766 - val_loss: 0.2896\n",
      "Epoch 4/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 201ms/step - accuracy: 0.8877 - loss: 0.2689 - val_accuracy: 0.8710 - val_loss: 0.2823\n",
      "Epoch 5/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 191ms/step - accuracy: 0.8827 - loss: 0.2579 - val_accuracy: 0.8953 - val_loss: 0.2532\n",
      "Epoch 6/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 170ms/step - accuracy: 0.8964 - loss: 0.2678 - val_accuracy: 0.8841 - val_loss: 0.2576\n",
      "Epoch 7/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 213ms/step - accuracy: 0.8930 - loss: 0.2446 - val_accuracy: 0.8935 - val_loss: 0.2402\n",
      "Epoch 8/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 192ms/step - accuracy: 0.8952 - loss: 0.2423 - val_accuracy: 0.9121 - val_loss: 0.2298\n",
      "Epoch 9/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 183ms/step - accuracy: 0.9160 - loss: 0.2005 - val_accuracy: 0.9009 - val_loss: 0.2299\n",
      "Epoch 10/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 218ms/step - accuracy: 0.9082 - loss: 0.2123 - val_accuracy: 0.9103 - val_loss: 0.2209\n",
      "Epoch 11/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 169ms/step - accuracy: 0.9153 - loss: 0.1936 - val_accuracy: 0.9084 - val_loss: 0.2505\n",
      "Epoch 12/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 197ms/step - accuracy: 0.9129 - loss: 0.2129 - val_accuracy: 0.9234 - val_loss: 0.2301\n",
      "Epoch 13/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 196ms/step - accuracy: 0.9415 - loss: 0.1541 - val_accuracy: 0.9009 - val_loss: 0.2422\n",
      "Epoch 14/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 184ms/step - accuracy: 0.9112 - loss: 0.1800 - val_accuracy: 0.9009 - val_loss: 0.2809\n",
      "Epoch 15/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 192ms/step - accuracy: 0.9220 - loss: 0.1799 - val_accuracy: 0.9140 - val_loss: 0.2436\n",
      "Epoch 16/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 191ms/step - accuracy: 0.9194 - loss: 0.1944 - val_accuracy: 0.8972 - val_loss: 0.2731\n",
      "Epoch 17/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 171ms/step - accuracy: 0.9437 - loss: 0.1478 - val_accuracy: 0.9028 - val_loss: 0.2683\n",
      "Epoch 18/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 189ms/step - accuracy: 0.9284 - loss: 0.1606 - val_accuracy: 0.9009 - val_loss: 0.2788\n",
      "Epoch 19/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 171ms/step - accuracy: 0.9430 - loss: 0.1309 - val_accuracy: 0.9065 - val_loss: 0.2545\n",
      "Epoch 20/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 177ms/step - accuracy: 0.9483 - loss: 0.1265 - val_accuracy: 0.8972 - val_loss: 0.2882\n",
      "Fold 1 Train loss: 0.1494, Train accuracy: 0.9383\n",
      "Fold 1 Test/Holdout loss: 0.2209, Test/Holdout accuracy: 0.9103\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step\n",
      "\n",
      "=================== FOLD 2/3 ===================\n",
      "Epoch 1/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 433ms/step - accuracy: 0.5623 - loss: 0.7145 - val_accuracy: 0.7589 - val_loss: 0.5023\n",
      "Epoch 2/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 221ms/step - accuracy: 0.7740 - loss: 0.4568 - val_accuracy: 0.8636 - val_loss: 0.3044\n",
      "Epoch 3/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 214ms/step - accuracy: 0.8292 - loss: 0.3540 - val_accuracy: 0.8916 - val_loss: 0.2612\n",
      "Epoch 4/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 175ms/step - accuracy: 0.8489 - loss: 0.3361 - val_accuracy: 0.8729 - val_loss: 0.2674\n",
      "Epoch 5/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 200ms/step - accuracy: 0.8598 - loss: 0.2906 - val_accuracy: 0.9047 - val_loss: 0.2429\n",
      "Epoch 6/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 178ms/step - accuracy: 0.8846 - loss: 0.2674 - val_accuracy: 0.8449 - val_loss: 0.3007\n",
      "Epoch 7/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 176ms/step - accuracy: 0.8794 - loss: 0.2802 - val_accuracy: 0.8523 - val_loss: 0.2603\n",
      "Epoch 8/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 197ms/step - accuracy: 0.9083 - loss: 0.2259 - val_accuracy: 0.9047 - val_loss: 0.2210\n",
      "Epoch 9/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 171ms/step - accuracy: 0.8969 - loss: 0.2399 - val_accuracy: 0.9065 - val_loss: 0.2270\n",
      "Epoch 10/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 198ms/step - accuracy: 0.9029 - loss: 0.2281 - val_accuracy: 0.9065 - val_loss: 0.2127\n",
      "Epoch 11/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 172ms/step - accuracy: 0.9169 - loss: 0.2124 - val_accuracy: 0.8991 - val_loss: 0.2201\n",
      "Epoch 12/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 183ms/step - accuracy: 0.9111 - loss: 0.2134 - val_accuracy: 0.8972 - val_loss: 0.2252\n",
      "Epoch 13/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 176ms/step - accuracy: 0.9103 - loss: 0.2241 - val_accuracy: 0.8953 - val_loss: 0.2377\n",
      "Epoch 14/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 175ms/step - accuracy: 0.8996 - loss: 0.2255 - val_accuracy: 0.9215 - val_loss: 0.2232\n",
      "Epoch 15/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 174ms/step - accuracy: 0.9175 - loss: 0.1812 - val_accuracy: 0.9084 - val_loss: 0.2205\n",
      "Epoch 16/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 181ms/step - accuracy: 0.9374 - loss: 0.1637 - val_accuracy: 0.9271 - val_loss: 0.2142\n",
      "Epoch 17/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 180ms/step - accuracy: 0.9221 - loss: 0.1871 - val_accuracy: 0.9028 - val_loss: 0.3081\n",
      "Epoch 18/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 189ms/step - accuracy: 0.9293 - loss: 0.1685 - val_accuracy: 0.8935 - val_loss: 0.2264\n",
      "Epoch 19/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 207ms/step - accuracy: 0.9426 - loss: 0.1486 - val_accuracy: 0.9140 - val_loss: 0.2049\n",
      "Epoch 20/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 166ms/step - accuracy: 0.9255 - loss: 0.1650 - val_accuracy: 0.9196 - val_loss: 0.2167\n",
      "Epoch 21/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 169ms/step - accuracy: 0.9353 - loss: 0.1530 - val_accuracy: 0.8991 - val_loss: 0.2139\n",
      "Epoch 22/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 168ms/step - accuracy: 0.9239 - loss: 0.1648 - val_accuracy: 0.8897 - val_loss: 0.2567\n",
      "Epoch 23/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 180ms/step - accuracy: 0.9452 - loss: 0.1430 - val_accuracy: 0.9196 - val_loss: 0.2143\n",
      "Epoch 24/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 174ms/step - accuracy: 0.9331 - loss: 0.1607 - val_accuracy: 0.9196 - val_loss: 0.2225\n",
      "Epoch 25/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 187ms/step - accuracy: 0.9292 - loss: 0.1690 - val_accuracy: 0.8879 - val_loss: 0.2786\n",
      "Epoch 26/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 170ms/step - accuracy: 0.9483 - loss: 0.1291 - val_accuracy: 0.8897 - val_loss: 0.2835\n",
      "Epoch 27/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 172ms/step - accuracy: 0.9415 - loss: 0.1477 - val_accuracy: 0.8916 - val_loss: 0.2907\n",
      "Epoch 28/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 173ms/step - accuracy: 0.9583 - loss: 0.1218 - val_accuracy: 0.8804 - val_loss: 0.2971\n",
      "Epoch 29/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 185ms/step - accuracy: 0.9418 - loss: 0.1492 - val_accuracy: 0.9196 - val_loss: 0.2372\n",
      "Fold 2 Train loss: 0.1427, Train accuracy: 0.9411\n",
      "Fold 2 Test/Holdout loss: 0.2049, Test/Holdout accuracy: 0.9140\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step\n",
      "\n",
      "=================== FOLD 3/3 ===================\n",
      "Epoch 1/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 826ms/step - accuracy: 0.6084 - loss: 0.7094 - val_accuracy: 0.7154 - val_loss: 0.4718\n",
      "Epoch 2/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 204ms/step - accuracy: 0.7698 - loss: 0.4275 - val_accuracy: 0.8034 - val_loss: 0.3553\n",
      "Epoch 3/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 199ms/step - accuracy: 0.8498 - loss: 0.3155 - val_accuracy: 0.8652 - val_loss: 0.3065\n",
      "Epoch 4/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 203ms/step - accuracy: 0.8661 - loss: 0.3031 - val_accuracy: 0.8633 - val_loss: 0.2837\n",
      "Epoch 5/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 197ms/step - accuracy: 0.8671 - loss: 0.2942 - val_accuracy: 0.8801 - val_loss: 0.2707\n",
      "Epoch 6/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 199ms/step - accuracy: 0.8868 - loss: 0.2375 - val_accuracy: 0.8914 - val_loss: 0.2687\n",
      "Epoch 7/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 194ms/step - accuracy: 0.9106 - loss: 0.2313 - val_accuracy: 0.9026 - val_loss: 0.2575\n",
      "Epoch 8/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 195ms/step - accuracy: 0.8957 - loss: 0.2227 - val_accuracy: 0.8914 - val_loss: 0.2541\n",
      "Epoch 9/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 168ms/step - accuracy: 0.9061 - loss: 0.2208 - val_accuracy: 0.8989 - val_loss: 0.2764\n",
      "Epoch 10/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 193ms/step - accuracy: 0.8991 - loss: 0.2193 - val_accuracy: 0.9007 - val_loss: 0.2428\n",
      "Epoch 11/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 167ms/step - accuracy: 0.9280 - loss: 0.1735 - val_accuracy: 0.8801 - val_loss: 0.2927\n",
      "Epoch 12/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 168ms/step - accuracy: 0.9169 - loss: 0.1927 - val_accuracy: 0.8764 - val_loss: 0.2984\n",
      "Epoch 13/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 179ms/step - accuracy: 0.9133 - loss: 0.2329 - val_accuracy: 0.8801 - val_loss: 0.2940\n",
      "Epoch 14/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 180ms/step - accuracy: 0.9285 - loss: 0.1822 - val_accuracy: 0.8914 - val_loss: 0.2980\n",
      "Epoch 15/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 166ms/step - accuracy: 0.9283 - loss: 0.1767 - val_accuracy: 0.8970 - val_loss: 0.2588\n",
      "Epoch 16/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 199ms/step - accuracy: 0.9457 - loss: 0.1554 - val_accuracy: 0.8933 - val_loss: 0.3046\n",
      "Epoch 17/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 168ms/step - accuracy: 0.9388 - loss: 0.1729 - val_accuracy: 0.9045 - val_loss: 0.2609\n",
      "Epoch 18/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 183ms/step - accuracy: 0.9518 - loss: 0.1288 - val_accuracy: 0.8951 - val_loss: 0.3039\n",
      "Epoch 19/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 172ms/step - accuracy: 0.9300 - loss: 0.1649 - val_accuracy: 0.9157 - val_loss: 0.2731\n",
      "Epoch 20/100\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 178ms/step - accuracy: 0.9299 - loss: 0.1599 - val_accuracy: 0.9101 - val_loss: 0.2946\n",
      "Fold 3 Train loss: 0.1662, Train accuracy: 0.9393\n",
      "Fold 3 Test/Holdout loss: 0.2428, Test/Holdout accuracy: 0.9007\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step\n",
      "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step\n",
      "\n",
      "--- Final Cross-Validation Scores ---\n",
      "Overall Train Log Loss (In-Fold): 0.1564\n",
      "Overall Valid Log Loss (Out-of-Fold): 0.2229\n"
     ]
    }
   ],
   "source": [
    "preds=myAngleCV(X_train, X_angle, X_test, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc7af7d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T06:30:12.534372Z",
     "iopub.status.busy": "2025-06-12T06:30:12.533360Z",
     "iopub.status.idle": "2025-06-12T06:30:12.563874Z",
     "shell.execute_reply": "2025-06-12T06:30:12.562946Z"
    },
    "papermill": {
     "duration": 0.135376,
     "end_time": "2025-06-12T06:30:12.565292",
     "exception": false,
     "start_time": "2025-06-12T06:30:12.429916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Submission for each day.\n",
    "submission = pd.DataFrame()\n",
    "submission['id']=test['id']\n",
    "submission['is_iceberg']=preds\n",
    "submission.to_csv('sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40a7c1d",
   "metadata": {
    "papermill": {
     "duration": 0.094,
     "end_time": "2025-06-12T06:30:12.767026",
     "exception": false,
     "start_time": "2025-06-12T06:30:12.673026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 44318,
     "sourceId": 7380,
     "sourceType": "competition"
    },
    {
     "datasetId": 7602020,
     "sourceId": 12076659,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 489.537026,
   "end_time": "2025-06-12T06:30:16.079474",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-12T06:22:06.542448",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
